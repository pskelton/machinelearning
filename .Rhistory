head(InsectSprays,n=15)
sb
sB
summary(InsectSprays[,2])
sapply(InsectSprays,class())
sapply(InsectSprays,class
)
fit <- lm(Count ~ Spray, data=InsectSprays)
fit <- lm(count ~ spray, data=InsectSprays)
summary(fit$coefficients)
summary(fit$coef)
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~spray-1, data=InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray,"C")
fit2 <- lm(count ~spray-1, data=InsectSprays)
fit2 <- lm(count ~spray2, data=InsectSprays)
summary(fit2)$coef
mean(sC)
(fit2$coef[2]-fi2t$coef[3])/1.6011
(fit2$coef[2]-fit2$coef[3])/1.6011
(fit$coef[2]-fit$coef[3])/1.6011
library(swirl)
swirl()
dim(hunger)
948
names(hunger)
fit <- lm(Numeric ~ Year, data=hunger)
summary(fit)$coef
lmf <- lm(Numeric ~ Year, data= hunger[hunger$sex=="Female"])
lmf <- lm(Numeric ~ Year, data=hunger[hunger$sex=="Female",])
lmf <- lm(Numeric[hunger$Sex=="Female"]  ~ Year[hunger$Sex=="Female"] , data=hunger)
lmF <-
| lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"],hunger)
lmF <-lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"],hunger)
lmM <-lm(Numeric[Sex=="Female"] ~ Year[Sex=="Male"],hunger)
lmM <- lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
lmBoth <- lm(Numeric ~ Year + Sex, data=hunger)
summary(lmBoth)
lmInter <- lm(Numeric ~ Year + Sex + Sex*Year, data=hunger)
summary(lmInter)
fit <- lm(y ~ x, out2)
plot(fit,which=1)
fitno <- lm(y~x,out2[-1,])
plot(fitno,which=1)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- sqrt(sum(fit$residuals^2)/fit$df.residual)
rstd <- resid(fit)/sigma*sqrt(1-hatvalues(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd,rstandard(fit)))
plot(fit,which=3)
plot(fit,which=2)
sigma1 <- sqrt(devian(fitno)-fitno$df.residual)
sigma1 <- sqrt(deviance(fitno)-fitno$df.residual)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
sqrt(1-hatvalues(fit)[1])resid(fit)[1] / sigma1*
resid(fit)[1] / sigma *sqrt(1-hatvalues(fit)[1])
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <- predict(fitno,out2) -predict(fit,out2)
sum(dy^2)/2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit,which=5)
0
library(datasets)
pairs(mtcars)
testt <- t.test(mpg~vs,data=mtcars)
testt
cor(mtcars$disp,mtcars$hp)
source('~/.active-rstudio-document', echo=TRUE)
summary(fitall)
par(mfrow=c(2, 2))
plot(fit8)
summary(fit8)
summary(fit5)
summary(fit8)
library(datasets)
?mtcars
view(mtcars)
View(mtcars)
library(swirl)
swirl()
rpg1()
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility~.,data=swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ .-Examination,data=swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility~Agriculture,data=swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, data=swiss)
anova(fit1,fit3)
deviance(fit3)
d <- deviance(fit3/43)
d <- deviance(fit3)/43
n <- (deviance(fit1)-deviance(fit3))/2
n/d
pf(n/d,2,43,lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1,fit3,fit5,fit6)
0
library(swirl)
swirl()
View(ravenData)
mdl <- glm( ravenWinNum ~ ravenScore , family = "binomial" , data = ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95,1)
var(rpois(1000, 50))
nxt()
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,0]
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
View(hits)
mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))
qpois(.95, mdl2$fitted.values[704])
0
library(mass)
?shuttle
?MASS
library(MASS)
?shuttle
mdl <- glm(use~wind, family = "binomial", data=shuttle)
summary(mdl)
coef(mdl)[1]/coef(mdl)[2]
odds <- exp(summary(fit)$coef)
odds[1] / odds[2] # 0.9686888
odds <- exp(summary(mdl)$coef)
odds[1] / odds[2] # 0.9686888
dat <- shuttle
dat$use <- as.numeric(dat$use == "auto")
fit <- glm(usse ~ as.factor(wind), data=shuttle, family="binomial")
odds <- exp(summary(fit)$coef)
odds[1] / odds[2] # 0.9686888
dat$use <- as.numeric(dat$use == "auto")
fit <- glm(use ~ as.factor(wind), data=dat, family="binomial")
odds <- exp(summary(fit)$coef)
odds[1] / odds[2] # 0.9686888
head(data)
head(dat)
summary(fit)
library(MASS)
dat<- shuttle
dat$use <- as.numeric(dat$use=="auto")
head(dat)
mdl <- glm( use ~ wind, family="binomial", data=dat)
summary(mdl)
odds <- exp(coef(mdl))
odds[1]/odds[2]
1/odds
odds[2]/odds[1]
dat$wind <- as.numeric(dat$wind=="head")
mdl <- glm( use ~ wind, family="binomial", data=dat)
sumamry(mdl)
summary(mdl)
exp(coef(mdl))
mdl2 <- glm( use ~ wind + as.factor(magn), family="binomial", data=dat)
summary(mdl2)
exp(coef(mdl2))
?InsectSprays
dat <- InsectSprays
head(InsectSprays)
mdl <- glm( count ~ as.factor(spray), family="poisson", data=dat)
summary(mdl)
mdl <- glm( count ~ as.factor(spray) -1, family="poisson", data=dat)
summary(mdl)
exp(coef(mdl))
mdl <- glm( count ~ as.factor(spray), family="poisson", data=dat)
exp(coef(mdl))
fit <- glm(count ~ as.factor(spray) + offset(log(count+1)),
family="poisson", data=InsectSprays)
fit2 <- glm(count ~ as.factor(spray) + offset(log(10)+log(count+1)),
family="poisson", data=InsectSprays)
summary(fit)$coef
summary(fit2)$coef
# Problem 6.
x <- -5 : 5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54,
3.87, 4.97)
knotPoint <- c(0)
spline <- sapply(knotPoint, function(knot) (x > knot) * (x - knot))
xMatrix <- cbind(1, x, spline)
fit <- lm(y ~ xMatrix - 1)
yhat <- predict(fit)
yhat
slope <- fit$coef[2] + fit$coef[3]
slope # 1.013
plot(x, y)
lines(x, yhat, col=2)
xMatrix
summary(fit)
xMatrixx
names(xMatrix)
View(xMatrix)
names(xMatrix) <- c("ones","xvals","spline")
View(xMatrix)
?"names"
View(xMatrix)
colnames(xMatrix) <- c("ones","xvals","spline")
View(xMatrix)
fit <- lm(y ~ xMatrix - 1)
summary(fit)
install.packages("caret")
install.packages(c("base64enc", "class", "curl", "devtools", "dplyr", "evaluate", "formatR", "git2r", "highr", "httpuv", "jsonlite", "knitr", "maps", "MASS", "mgcv", "mime", "nlme", "nnet", "PKI", "quantmod", "quantreg", "R6", "Rcpp", "rJava", "rmarkdown", "scales", "spatial", "tidyr", "xml2"))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
require(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
head(predictors)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(adData)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
View(adData)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
?alzheimer
??alzheimer
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
log(0)
head(training$Superplasticizer)
hist(log(training$Superplasticizer+1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(predictors)
startil <- grep("IL",names(predictors))
startil <- grep("IL",names(predictors),value=T)
startil
startil <- grep("^IL",names(predictors),value=T)
startil <- grep("^IL",names(predictors),value=T)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
startil <- grep("^IL",names(predictors),value=T)
ss <- training[,grep('^IL', names(predictors) )]
preProc <- preProcess(ss, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc$rotation # 9
grep('^IL', names(predictors) )
grep('^IL', names(predictors) ,value=T)
ss <- training[,grep("^IL", names(predictors) )]
preProc <- preProcess(ss, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc$rotation # 9
View(ss)
View(training)
ss <- training[,grep("^IL", names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc$rotation # 9
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
startil <- grep("^IL",names(training))
head(training)
startil <- c(1,startil)
newtrain <- training[,startil]
head(newtrain)
newtest <- testing[,startil]
model1 <- train(diagnosis~., method="glm", data=newtrain)
install.packages('e1071', dependencies=TRUE)
model1 <- train(diagnosis~., method="glm", data=newtrain)
predict1 <- predict(model1,newdata = newtest)
??confusionMatrix
conf1 <- confusionMatrix(predict1,newtest$diagnosis)
conf1
model2 <- train(diagnosis~.,method="glm",preProcess="pca", data=newtrain, trControl=trainControl(preProcOptions = list(thresh=0.8)))
predict2 <- predict(model2,newdata = newtest)
conf2 <- confusionMatrix(predict2,newtest$diagnosis)
conf2
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
intrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=F)
training <- segmentationOriginal[intrain,]
testing <- segmentationOriginal[-intrain,]
dim(training)
dim(testing)
modfit <- train(Case ~ . ,method="rpart",data=training)
modfit
plot(modfit)
plot(modfit$finalModel)
plot(modfit$finalModel,uniform=T)
text(modfit$finalModel, cex=0.8)
set.seed(125)
intrain <- segmentationOriginal$Case == "Train"
training <- segmentationOriginal[intrain,]
testing <- segmentationOriginal[!intrain,]
modfit <- train(Case ~ . ,method="rpart",data=training
)
View(testing)
modfit <- train(Class ~ . ,method="rpart",data=training
)
plot(modfit$finalModel,uniform=T)
text(modfit$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
modelfit <- train(Area ~ ., method="tree", data=olive)
modelfit <- train(Area ~ ., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modelfit$finalModel,newdata)
head(olive)
table(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
modelfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl)
modelfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predicttrain <- predict(modelfit,trainSA)
predicttest <- predict(modelfit,testSA)
missclass(trainSA$chd,predicttrain)
missClass(trainSA$chd,predicttrain)
missClass(testSA$chd,predicttest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train <- vowel.train
test <- vowel.test
train$y <- as.factor(train$y)
test$y <- as.factor(test$y)
set.seed(33833)
modelfit <- train(y ~ ., method="rpart", data=train)
?varImp
varImp(modelfit)
modelfit <- train(y ~ ., method="rf", data=train)
varImp(modelfit)
set.seed(33833)
modelfit <- train(y ~ ., method="rf", data=train)
varImp(modelfit)
---
dir()
setwd("r programming")
dir()
setwd("machine learn")
dir(0)
dir()
traindataurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testdataurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
traindatapath <- "data\\pml-training.csv"
testdatapath <- "data\\pml-testing.csv"
if ( !file.exists( traindatapath ) ){
download.file( traindataurl, destfile = traindatapath )
download.file( testdataurl, destfile = testdatapath )
}
training <- read.csv( traindatapath )
testing <- read.csv( testdatapath )
dim( training )
head( training, n=2 )
sum( is.na( training ) )
str(training)
training <- Filter( function(x) (sum(x=="")<500), training)
sum( is.na( training ) )
View(training)
table(training$user_name)
testtraining <- training[,-(1:7)]
View(testtraining)
training <- training[ ,-(1:7) ]
library( caret )
intrain <- createDataPartition( y=training$classe, p=0.7, list=FALSE )
View(intrain)
trainsplit <- training[ intrain, ]
testsplit <- training[ -intrain, ]
??doMC
??parallel
library(doMC)
install.packages("doMC")
library(parallel, quietly=T)
library(doParallel, quietly=T)
## Turn on PP (leave at least 1 core free so your machine is still usable when doing the calc)
cluster             <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
modelfit <- train( factor( trainsplit$classe ) ~ . , method="rf", data=trainsplit )
library(parallel, quietly=T)
library(doParallel, quietly=T)
install.packages("doParallel")
library(doParallel, quietly=T)
cluster             <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
modelfit <- train( factor( trainsplit$classe ) ~ . , method="rf", data=trainsplit, trControl = trainControl(method="cv", number=5) )
stopCluster(cluster)
library(parallel, quietly=T)
library(doParallel, quietly=T)
## Turn on PP (leave at least 1 core free so your machine is still usable when doing the calc)
cluster             <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
modelfit <- train( factor( trainsplit$classe ) ~ . , method="rf", data=trainsplit, trControl = trainControl(method="cv", number=10) )
## Turn off PP
stopCluster(cluster)
modelfit
confmat <- confusionMatrix( testsplit$classe, predict( modelfit, testsplit$classe ))
confmat <- confusionMatrix( testsplit$classe, predict( modelfit, testsplit ))
confmat
confmat1 <- confusionMatrix( trainsplit$classe, predict( modelfit, trainsplit ))
confmat2 <- confusionMatrix( testsplit$classe, predict( modelfit, testsplit ))
confmat1
confmat2
results <- predict( modelfit, testing )
as.char(results)
as.character(results)
confmat1 <- predict(modelfit)
confmat1
confmat1 <- confusionMatrix( trainsplit$classe, predict( modelfit ))
confmat1
testrfcv <- rfcv(trainsplit, trainsplit$classe)
testrfcv
library(parallel, quietly=T)
library(doParallel, quietly=T)
## Turn on PP - With thanks to RAY JONES (TA)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
testrfcv <- rfcv(trainsplit[,-classe], trainsplit[,classe])
testrfcv <- rfcv(trainsplit[,-classe], trainsplit$classe)
testrfcv <- rfcv(trainsplit[,-60], trainsplit$classe)
library(parallel, quietly=T)
library(doParallel, quietly=T)
## Turn on PP - With thanks to RAY JONES (TA)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
testrfcv <- rfcv(trainsplit[,-60], trainsplit$classe)
findCorrelation(cor(trainsplit))
findCorrelation(cor(trainsplit[,-60]))
findCorrelation(cor(trainsplit[,-53]))
View(trainsplit)
testrfcv <- rfcv(trainsplit[,-53], trainsplit$classe)
testrfcv$error.cv
save.image("~/r programming/machine learn/machinelearn.RData")
load("~/r programming/machine learn/machinelearn.RData")
confmat2
